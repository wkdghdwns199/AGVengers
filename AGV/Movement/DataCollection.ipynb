{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2장. Data Collection\n",
    "만약 충돌 회피 예제를 실행했다면, 다음 세 단계에 익숙할 것입니다.  \n",
    "- 데이터 수집 Data collection\n",
    "- 훈련 Train Model\n",
    "- 배포 Live Demo\n",
    "\n",
    "이 챕터에서는 똑같은 작업을 수행할 것입니다.  \n",
    "하지만, 분류 대신에 회귀(Regression)라는 다른 기본 기술을 배우게 될 것입니다.  \n",
    "이 회귀 기술은 인공지능 무인운반차량(AGV)이 도로(또는 실제로는 어떤 경로나 목표 지점이든)를 따라가도록 할 것입니다.  \n",
    "경로상의 다양한 위치에 인공지능 무인운반차량(AGV)을 배치합니다. (중심으로부터의 오프셋, 다른 각도 등)\n",
    "인공지능 무인운반차량(AGV)의 라이브 카메라 화면을 출력합니다.  \n",
    "버튼 위젯을 사용하여, 인공지능 무인운반차량(AGV)이 이동해야 할 목표 방향에 해당하는 '녹색 점'을 이미지에 배치합니다.  \n",
    "카메라의 이미지와 이 녹색 점의 X, Y 값을 저장합니다.  \n",
    "그런 다음, 훈련 챕터에서 우리의 레이블의 X, Y 값을 예측할 신경망을 훈련시킬 것입니다. 라이브 데모에서는 예측된 X, Y 값을 사용하여 근사적인 조향 값을 계산할 것입니다.  \n",
    "\n",
    "카메라의 라이브 비디오 피드를 살펴봅니다.  \n",
    "인공지능 무인운반차량(AGV)이 따라야 할 경로를 상상해봅니다(도로에서 벗어나지 않도록 해야 할 거리를 대략적으로 추정해 봅니다).  \n",
    "인공지능 무인운반차량(AGV)이 도로 밖으로 벗어나지 않고 직접 목표지점으로 향할 수 있도록 이 경로를 따라서 목표를 가능한 멀리 배치합니다.  \n",
    "예를 들어, 아주 직선적인 도로인 경우 지평선에 배치할 수 있습니다. 급한 커브인 경우 인공지능 무인운반차량(AGV)에게 너무 가까이 배치하여 경계를 벗어나지 않도록 해야 할 수도 있습니다.  \n",
    "\n",
    "## 라이브러리 가져오기   \n",
    "\"데이터 수집\" 목적에 필요한 모든 라이브러리를 가져오는 것으로 시작해 보겠습니다. 주로 이미지를 시각화하고 라벨이 달린 이미지를 저장하기 위해 OpenCV를 사용할 것입니다. 이미지 이름 지정에는 uuid, datetime과 같은 라이브러리가 사용됩니다.  \n",
    "\n",
    "코드를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n"
     ]
    }
   ],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from SCSCtrl import TTLServo\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카메라 각도 세팅하기  \n",
    "Data를 수집할 때 사용한 이미지와 맞춰서 Road Following 을 해야 합니다.  \n",
    "일정한 각도로 들어오는 이미지가 필요하기 때문에, 고정된 카메라 각도를 사용합니다.   \n",
    "> 주의 : 서보모터의 조립 방향에 따라 각도가 다를 수 있습니다.\n",
    "본인의 서보모터 방향에 유의하여 코드를 실행합니다.  \n",
    "이 코드의 목표는 Data 수집할 때 카메라 각도와 Road Following을 할 때 카메라 각도를 일치시키는 데에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Ready!\n"
     ]
    }
   ],
   "source": [
    "TTLServo.servoAngleCtrl(5, 50, 1, 100)\n",
    "print('Camera Ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGV 제어를 위한 컨트롤러 추가하기\n",
    "기존 Sample 코드에서는 조이스틱 컨트롤러를 사용하여 인공지능 무인운반차량(AGV)을 이동시키고, 이미지를 저장하는 방식을 사용하였습니다.  \n",
    "하지만, 한번에 대량의 조이스틱 컨트롤러를 사용할 경우, 서로 다른 인공지능 무인운반차량(AGV)을 제어할 수 있다는 점이 발견되어, 버튼 위젯을 사용하여 인공지능 무인운반차량(AGV)을 map에서 이동시키고, 가야할 경로를 설정하고 이미지를 저장하도록 변경하였습니다.  \n",
    "\n",
    "코드를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='forward', layout=Layout(align_self='center', height='80px', width='100px'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create buttons\n",
    "button_layout = widgets.Layout(width='100px', height='80px', align_self='center')\n",
    "stop_button = widgets.Button(description='stop', button_style='danger', layout=button_layout)\n",
    "forward_button = widgets.Button(description='forward', layout=button_layout)\n",
    "backward_button = widgets.Button(description='backward', layout=button_layout)\n",
    "left_button = widgets.Button(description='left', layout=button_layout)\n",
    "right_button = widgets.Button(description='right', layout=button_layout)\n",
    "# 레이아웃 생성 후,버튼 5개 생성\n",
    "\n",
    "# display buttons\n",
    "middle_box = widgets.HBox([left_button, stop_button, right_button], layout=widgets.Layout(align_self='center'))\n",
    "controls_box = widgets.VBox([forward_button, middle_box, backward_button])\n",
    "display(controls_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(change):\n",
    "    robot.stop()\n",
    "    \n",
    "def step_forward(change):\n",
    "    robot.forward(0.4)\n",
    "\n",
    "def step_backward(change):\n",
    "    robot.backward(0.4)\n",
    "\n",
    "def step_left(change):\n",
    "    robot.left(0.3)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "\n",
    "def step_right(change):\n",
    "    robot.right(0.3)\n",
    "    time.sleep(0.5)\n",
    "    robot.stop()\n",
    "\n",
    "stop_button.on_click(stop)\n",
    "forward_button.on_click(step_forward)\n",
    "backward_button.on_click(step_backward)\n",
    "left_button.on_click(step_left)\n",
    "right_button.on_click(step_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 버튼 위젯을 눌러서 인공지능 무인운반차량(AGV)이 원활하게 이동하는 지 체크합니다.  \n",
    "## 데이터 수집 경로 설정\n",
    "아래 코드에서 현재 디렉토리에 ‘dataset_xy_test’ 라는 폴더를 생성하고 data를 수집합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories not created becasue they already exist\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = 'dataset_xy'\n",
    "\n",
    "try:\n",
    "    os.makedirs(DATASET_DIR)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카메라 송출하기\n",
    "다음은, 카메라를 사용해서, 두 개의 화면을 송출합니다.  \n",
    "하나는 실시간 영상 원본을, 다른 하나는 인공지능 무인운반차량(AGV)이 나아가야 할 방향인 ‘target’의 \n",
    "위치를 표시할 화면입니다.  \n",
    "두 개의 x축, y축 slider를 이용해 ‘target’의 위치를 정할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=0.0, description='x', max=1.0, min=-1.0, step=0.001), FloatSlider(value=0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera = Camera()\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "target_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "x_slider = widgets.FloatSlider(min=-1.0, max=1.0, step=0.001, description='x')\n",
    "y_slider = widgets.FloatSlider(min=-1.0, max=1.0, step=0.001, description='y')\n",
    "\n",
    "def display_xy(camera_image):\n",
    "    image = np.copy(camera_image)\n",
    "    x = x_slider.value\n",
    "    y = y_slider.value\n",
    "    x = int(x * 224 / 2 + 112)\n",
    "    y = int(y * 224 / 2 + 112)\n",
    "    image = cv2.circle(image, (x, y), 8, (0, 255, 0), 3)\n",
    "    image = cv2.circle(image, (112, 224), 8, (0, 0,255), 3)\n",
    "    image = cv2.line(image, (x,y), (112,224), (255,0,0), 3)\n",
    "    jpeg_image = bgr8_to_jpeg(image)\n",
    "    return jpeg_image\n",
    "\n",
    "time.sleep(1)\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "traitlets.dlink((camera, 'value'), (target_widget, 'value'), transform=display_xy)\n",
    "display(widgets.HBox([image_widget, target_widget]))\n",
    "\n",
    "count_widget = widgets.IntText(description='count',\n",
    " value=len(glob.glob(os.path.join(DATASET_DIR, '*.jpg'))))\n",
    "save_button = widgets.Button(description='Save', button_style='success')\n",
    "\n",
    "display(widgets.VBox([x_slider, y_slider, count_widget, save_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집하기\n",
    "아래 코드를 실행해서 Save 버튼을 누르면, data가 수집됩니다.  \n",
    "수집할 데이터는 현재 카메라의 시야에서 인공지능 무인운반차량(AGV)이 나아가야 하는 방향을 가리키는 녹색 점의 x,y 좌표입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_uuid(x, y):\n",
    "    return 'xy_%03d_%03d_%s' % (x * 50 + 50, y * 50 + 50, uuid1())\n",
    "\n",
    "def save_snapshot():\n",
    "    uuid = xy_uuid(x_slider.value, y_slider.value)\n",
    "    image_path = os.path.join(DATASET_DIR, uuid + '.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image_widget.value)\n",
    "    count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "    \n",
    "save_button.on_click(lambda x: save_snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 수집 절차는 다음과 같습니다.  \n",
    "1. Camera 의 실시간 영상을 보고, AGV가 나아가야 하는 target의 위치에 녹색 점을 둔다.\n",
    "2. save 버튼을 눌러서 저장한다.\n",
    "3. 수집한 데이터 파일은 dataset_xy 폴더에 저장되며, 아래와 같은 이름 형식을 지닌다.\n",
    "> \\\"xy_xValue_yValue_UUID.jpg\\\"\n",
    "\n",
    "train_model 챕터에서 model 을 학습시킬 때는 이미지 파일을 불러와서 파일 이름에서 x,y 좌표 값을 파싱해서 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 종료하기\n",
    "다른 노트북에서도 사용할 수 있도록 카메라를 종료한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.stop()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 압축해서 내보내기\n",
    "data 파일을 외부 클라우드 머신에 옮기고 싶다면, 아래 명령어를 이용해서 압축한다.  \n",
    "이제 다음 train_model 로 이동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r -q road_following_{DATASET_DIR}.zip {DATASET_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
